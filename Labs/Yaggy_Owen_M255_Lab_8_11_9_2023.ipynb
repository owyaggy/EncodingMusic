{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd489f30f1bdaad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T04:02:43.578141Z",
     "start_time": "2023-11-12T04:02:42.971333Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Visualisation dependencies\n",
    "import textwrap\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3160722ac7adcc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### List of all Beautiful Soup methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb78a957b2a6b987",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T04:02:43.579294Z",
     "start_time": "2023-11-12T04:02:43.535627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['append',\n 'childGenerator',\n 'children',\n 'clear',\n 'css',\n 'decode',\n 'decode_contents',\n 'decompose',\n 'decomposed',\n 'default',\n 'descendants',\n 'encode',\n 'encode_contents',\n 'endData',\n 'extend',\n 'extract',\n 'fetchNextSiblings',\n 'fetchParents',\n 'fetchPrevious',\n 'fetchPreviousSiblings',\n 'find',\n 'findAll',\n 'findAllNext',\n 'findAllPrevious',\n 'findChild',\n 'findChildren',\n 'findNext',\n 'findNextSibling',\n 'findNextSiblings',\n 'findParent',\n 'findParents',\n 'findPrevious',\n 'findPreviousSibling',\n 'findPreviousSiblings',\n 'find_all',\n 'find_all_next',\n 'find_all_previous',\n 'find_next',\n 'find_next_sibling',\n 'find_next_siblings',\n 'find_parent',\n 'find_parents',\n 'find_previous',\n 'find_previous_sibling',\n 'find_previous_siblings',\n 'format_string',\n 'formatter_for_name',\n 'get',\n 'getText',\n 'get_attribute_list',\n 'get_text',\n 'handle_data',\n 'handle_endtag',\n 'handle_starttag',\n 'has_attr',\n 'has_key',\n 'index',\n 'insert',\n 'insert_after',\n 'insert_before',\n 'isSelfClosing',\n 'is_empty_element',\n 'known_xml',\n 'new_string',\n 'new_tag',\n 'next',\n 'nextGenerator',\n 'nextSibling',\n 'nextSiblingGenerator',\n 'next_elements',\n 'next_siblings',\n 'object_was_parsed',\n 'parentGenerator',\n 'parents',\n 'parserClass',\n 'popTag',\n 'prettify',\n 'previous',\n 'previousGenerator',\n 'previousSibling',\n 'previousSiblingGenerator',\n 'previous_elements',\n 'previous_siblings',\n 'pushTag',\n 'recursiveChildGenerator',\n 'renderContents',\n 'replaceWith',\n 'replaceWithChildren',\n 'replace_with',\n 'replace_with_children',\n 'reset',\n 'select',\n 'select_one',\n 'self_and_descendants',\n 'setup',\n 'smooth',\n 'string',\n 'string_container',\n 'strings',\n 'stripped_strings',\n 'text',\n 'unwrap',\n 'wrap']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(BeautifulSoup) if m[0].islower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367421620c62416",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7054664105548c34",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T04:02:43.579592Z",
     "start_time": "2023-11-12T04:02:43.543755Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXML(url):\n",
    "    # request for xml document of given url\n",
    "    response = requests.get(url)    \n",
    "    # response will be provided in JSON format\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdaf5ea8393656e5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T04:02:43.763235Z",
     "start_time": "2023-11-12T04:02:43.551785Z"
    }
   },
   "outputs": [],
   "source": [
    "xml_document = getXML('https://crimproject.org/mei/CRIM_Model_0019.mei')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a572a94ad3beef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Convert into Beautiful Soup Object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a82b400c174d5f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T04:02:43.894875Z",
     "start_time": "2023-11-12T04:02:43.766109Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owenyaggy/code/EncodingMusic/venv/lib/python3.10/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(xml_document, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84fd8be14648368",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visualizing XML as Network Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44a0d4693e37f49",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T04:09:44.283511Z",
     "start_time": "2023-11-12T04:09:44.272672Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_element(tag: bs4.element.Tag, wrap_length=20, exclude=[]):\n",
    "    attrs_list = []\n",
    "    \n",
    "    for a, v in tag.attrs.items():\n",
    "        if a in exclude:\n",
    "            continue\n",
    "        attrs_list.append(f\"{a}={v}\")\n",
    "    \n",
    "    formatted_string = f\"{tag.name} ({' '.join(attrs_list)})\" if attrs_list else tag.name\n",
    "    \n",
    "    return textwrap.fill(formatted_string, wrap_length)\n",
    "\n",
    "\n",
    "\n",
    "def create_network(tag: bs4.element.Tag, with_attributes: bool = False, attrs_to_exclude=[]):\n",
    "\n",
    "    all_tags = [tag] + tag.find_all()\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for node in all_tags:\n",
    "        depth = len(list(node.parents))\n",
    "        G.add_node(\n",
    "                   id(node), \n",
    "                   label=format_element(node, exclude=attrs_to_exclude) if with_attributes else node.name,\n",
    "                   value=len(list(node.descendants)),\n",
    "                   group=depth,\n",
    "                   level=depth,\n",
    "                   scaling={'label': {'enabled': True}},\n",
    "                  )\n",
    "\n",
    "    for node in all_tags:\n",
    "        for child in node.children:\n",
    "            if child.name:\n",
    "                G.add_edge(id(node), id(child), \n",
    "                           arrows='to',\n",
    "                       id=f\"{id(node)}_{node.name}|{id(child)}_{child.name}\")\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def display_network(network, \n",
    "                    filename=\"tmp.html\", \n",
    "                    width=900, \n",
    "                    height=900, \n",
    "                    bgcolor=\"white\",\n",
    "                    font_color=\"black\",\n",
    "                    notebook=True,\n",
    "                   ):\n",
    "\n",
    "    nt = Network(notebook=notebook, width=width, height=height, bgcolor=bgcolor, font_color=font_color, cdn_resources='remote')\n",
    "    nt.from_nx(network)\n",
    "\n",
    "    return nt.show(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847e9bd97023f58a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create network of single measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7561c831da241d58",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T04:09:46.579490Z",
     "start_time": "2023-11-12T04:09:46.544007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_measure.html\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x12a1fa950>",
      "text/html": "\n        <iframe\n            width=\"900\"\n            height=\"900\"\n            src=\"simple_measure.html\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_network = create_network(soup.find(\"measure\", {\"n\": 1}))\n",
    "display_network(measure_network, filename=\"simple_measure.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65e3355045b60a0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T04:02:43.950771Z",
     "start_time": "2023-11-12T04:02:43.927441Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
